PROJECT:
  PROJECT_NAME: "cad-alexnet-classification"

DATA:
  LOCAL_ROOT_DIR: "file://data/raw"
  LOCAL_OUTPUT_DIR: "file://results/"
  EVAL_DIR: "data/raw/valid"

  S3_BUCKET: "cad-brbh-datascience"
  S3_INPUT_DIR: "s3://cad-brbh-datascience/alexnet_image_classification/"
  S3_TRAIN_DIR: "s3://cad-brbh-datascience/alexnet_image_classification/data/processed/train/"
  S3_VAL_DIR: "s3://cad-brbh-datascience/alexnet_image_classification/data/processed/valid/"
  S3_CHECKPOINT_DIR: "s3://cad-brbh-datascience/alexnet_image_classification/checkpoints"
  S3_OUTPUT_DIR: "s3://cad-brbh-datascience/alexnet_image_classification/models"

MODEL:
  NUM_CLASSES: 3
  RESIZE: 224

TRAINING:
  EPOCHS: 70
  BATCH_SIZE: 64
  LEARNING_RATE: 0.0015

OPTIMIZER:
  OPTIMIZER: "SGD"
  SGD_MOMENTUM: 0.85

REGULARIZATION:
  WEIGHT_DECAY: 0.01

SCHEDULER:
  SCHEDULER: "StepLR"
  STEP_SIZE: 10
  GAMMA: 0.05

AUGMENTATION:
  AUGMENTATION_TRANSFORMATIONS:
    p: 0.4
    shift_limit: 0.05
    scale_limit: 0.05
    rotate_limit: 5
    border_mode: "reflect_101"


# Weight decay is used to prevent zig-zagging during training. Less WD -> more zig-zagging.
# SGD momentum is used to accelerate convergence. More momentum -> faster convergence.